{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc69088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 9600355742670163293\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4178575360\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1826886343502233441\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7320dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ca0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfa33c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14000 images belonging to 7 classes.\n",
      "Found 3506 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#학습셋의 변형을 설정하는 부분입니다. \n",
    "train_datagen = ImageDataGenerator(rescale=1./255,          # 주어진 이미지의 크기를 설정합니다.\n",
    "                                  #horizontal_flip=True,     # 수평 대칭 이미지를 50% 확률로 만들어 추가합니다.\n",
    "                                  #width_shift_range=0.1,    # 전체 크기의 15% 범위에서 좌우로 이동합니다.\n",
    "                                  #height_shift_range=0.1,   # 마찬가지로 위, 아래로 이동합니다.\n",
    "                                  #rotation_range=5,        # 정해진 각도만큼 회전시킵니다.\n",
    "                                  #shear_range=0.7,         # 좌표 하나를 고정시키고 나머지를 이동시킵니다.\n",
    "                                  #zoom_range=1.2,          # 확대 또는 축소시킵니다.\n",
    "                                  #vertical_flip=True,      # 수직 대칭 이미지를 만듭니다.\n",
    "                                  #fill_mode='nearest'      # 빈 공간을 채우는 방법입니다. nearest 옵션은 가장 비슷한 색으로 채우게 됩니다.\n",
    "                                  )  \n",
    "train_generator = train_datagen.flow_from_directory('testC/clothes/train',\n",
    "                                                   target_size=(220, 260),\n",
    "                                                   batch_size=5,\n",
    "                                                   class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory('testC/clothes/test',\n",
    "                                                   target_size=(220, 260),\n",
    "                                                   batch_size=5,\n",
    "                                                   class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67396f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 220, 260, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 220, 260, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 220, 260, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 110, 130, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 110, 130, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 110, 130, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 55, 65, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 55, 65, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 55, 65, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 55, 65, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 27, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 27, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 27, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 27, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 13, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 13, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 13, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 13, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model = VGG16(weights='imagenet', include_top = False,\n",
    "                      input_shape=(220, 260,3))\n",
    "transfer_model.trainable = False\n",
    "transfer_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a49506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 6, 8, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24576)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1572928   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,288,071\n",
      "Trainable params: 1,573,383\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finetune_model = models.Sequential()\n",
    "finetune_model.add(transfer_model)\n",
    "finetune_model.add(layers.Flatten())\n",
    "finetune_model.add(layers.Dense(64, activation = 'relu'))\n",
    "finetune_model.add(layers.Dropout(0.5))\n",
    "finetune_model.add(layers.Dense(7, activation = 'softmax'))\n",
    "finetune_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbd45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=optimizers.Adam(learning_rate=0.0002),\n",
    "             metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af297300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ce0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2800/2800 [==============================] - 157s 55ms/step - loss: 1.1173 - accuracy: 0.5493 - val_loss: 0.7607 - val_accuracy: 0.7151\n",
      "Epoch 2/20\n",
      "2800/2800 [==============================] - 155s 56ms/step - loss: 0.8612 - accuracy: 0.6436 - val_loss: 0.6573 - val_accuracy: 0.7442\n",
      "Epoch 3/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.7769 - accuracy: 0.6788 - val_loss: 0.5927 - val_accuracy: 0.7815\n",
      "Epoch 4/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.7305 - accuracy: 0.6998 - val_loss: 0.5885 - val_accuracy: 0.7741\n",
      "Epoch 5/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.6892 - accuracy: 0.7146 - val_loss: 0.5582 - val_accuracy: 0.7958\n",
      "Epoch 6/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.6519 - accuracy: 0.7286 - val_loss: 0.5829 - val_accuracy: 0.7983\n",
      "Epoch 7/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.6130 - accuracy: 0.7542 - val_loss: 0.5933 - val_accuracy: 0.7815\n",
      "Epoch 8/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.6008 - accuracy: 0.7559 - val_loss: 0.5784 - val_accuracy: 0.7963\n",
      "Epoch 9/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.5665 - accuracy: 0.7674 - val_loss: 0.5658 - val_accuracy: 0.8055\n",
      "Epoch 10/20\n",
      "2800/2800 [==============================] - 156s 56ms/step - loss: 0.5549 - accuracy: 0.7741 - val_loss: 0.5711 - val_accuracy: 0.7824\n"
     ]
    }
   ],
   "source": [
    "history = finetune_model.fit(\n",
    "       train_generator,\n",
    "       epochs=20,\n",
    "       validation_data=test_generator,\n",
    "       callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900cb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
